"""
This file contains the code for evaluating the performance of the DSWizard.
"""

import os
import sys
import json
import pdb
from typing import List

from .llm.llm import call_llm_json_output

evidence_alignment_prompt = """
You are a biomedical expert evaluating the factual alignment between ground-truth scientific observations and evidence statements generated by an AI agent.

Your task is to assess **each ground-truth evidence statement** and determine whether it is:

- **Supported**: The generated evidence affirms or accurately reflects the ground-truth.
- **Contradicted**: The generated evidence disputes or reports conflicting information.
- **Missed**: The generated evidence does not address or mention the ground-truth information.

**Do not consider wording, phrasing, or style â€” only evaluate factual content.**

---

### Input

**Ground-Truth Evidence**
{gt_str}

**Generated Evidence**
{evidence}

---

### Output

Produce a JSON object indicating, for each ground-truth evidence statement, whether it is **Supported**, **Contradicted**, or **Missed** based on the generated evidence.

**Output Format**
```json
{{
  "eval": [
    {{
      "evidence_id": "0",  // Index of the ground-truth evidence (starting from 0)
      "alignment": "Supported"  // One of: "Supported", "Contradicted", "Missed"
    }},
    {{
      "evidence_id": "1",
      "alignment": "Contradicted"
    }},
    ...
    // Add entries for all ground-truth evidence items
  ]
}}
```
"""

def _parse_evidence_alignment_output(response: dict) -> List[dict]:
    """Parse the evidence alignment output"""
    try:
        eval_list = json.loads(response)["eval"]
    except Exception as e:
        eval_list = []
    return eval_list

def llm_evaluate_evidence_alignment(
    gt_evidences: List[str],
    generated_evidences: List[str],
    llm: str = "gpt-4o-mini",
):
    """Evaluate the evidence alignment"""
    gt_str = []
    for e_idx, gt_evidence in enumerate(gt_evidences):
        gt_str.append(f"Ground-truth evidence {e_idx}: {gt_evidence}\n")
    gt_str = "\n".join(gt_str)
    evidence_str = "\n".join(generated_evidences)
    response = call_llm_json_output(
        prompt_template=evidence_alignment_prompt,
        inputs={"gt_str": gt_str, "evidence": evidence_str},
        llm=llm,
        max_completion_tokens=256,
        temperature=0.0,
    )
    eval_list = _parse_evidence_alignment_output(response)
    return eval_list

